% 该文件对 DeepDropout 函数进行了测试。

clear all

X  = zeros(5, 5, 5);

X(:, :, 1) = [ 0 1 1 0 0;
               0 0 1 0 0;
               0 0 1 0 0;
               0 0 1 0 0;
               0 1 1 1 0
             ];

X(:, :, 2) = [ 1 1 1 1 0;
               0 0 0 0 1;
               0 1 1 1 0;
               1 0 0 0 0;
               1 1 1 1 1
             ];

X(:, :, 3) = [ 1 1 1 1 0;
               0 0 0 0 1;
               0 1 1 1 0;
               0 0 0 0 1;
               1 1 1 1 0
             ];

X(:, :, 4) = [ 0 0 0 1 0;
               0 0 1 1 0;
               0 1 0 1 0;
               1 1 1 1 1;
               0 0 0 1 0
             ];

X(:, :, 5) = [ 1 1 1 1 1;
               1 0 0 0 0;
               1 1 1 1 0;
               0 0 0 0 1;
               1 1 1 1 0
             ];

D = [ 1 0 0 0 0;
      0 1 0 0 0;
      0 0 1 0 0;
      0 0 0 1 0;
      0 0 0 0 1
    ]; % one-hot 编码

W1 = 2*rand(20, 25) - 1; % 随机初始化权重参数
                         % 每个元素的值在 -1 到 1 之间
W2 = 2*rand(20, 20) - 1; % 随机初始化权重参数
                         % 每个元素的值在 -1 到 1 之间
W3 = 2*rand(20, 20) - 1; % 随机初始化权重参数
                         % 每个元素的值在 -1 到 1 之间
W4 = 2*rand( 5, 20) - 1; % 随机初始化权重参数
                         % 每个元素的值在 -1 到 1 之间

% 训练模型
% 注意这里使用了 20000 次迭代（之前是 10000 次），这是因为采取了 dropout 策略的神经网络的权重更新效率相对较低
for epoch = 1:20000
  [W1, W2, W3, W4] = DeepDropout(W1, W2, W3, W4, X, D);
end

% 使用模型进行预测
% 特别注意，和训练不同，在预测的过程中不能使用 dropout 策略屏蔽掉某些节点！
N = 5;
for k = 1:N
  x  = reshape(X(:, :, k), 25, 1);
  v1 = W1*x;
  y1 = Sigmoid(v1);

  v2 = W2*y1;
  y2 = Sigmoid(v2);

  v3 = W3*y2;
  y3 = Sigmoid(v3);

  v  = W4*y3;
  y  = Softmax(v)
end
